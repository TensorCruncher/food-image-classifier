{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6XIV+o4E2gdbkpSwxWiei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TensorCruncher/food-image-classifier/blob/main/food_classifier_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction"
      ],
      "metadata": {
        "id": "A8tXP9ChosXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In this notebook üìò we will fine tune an EffNetB2 neural network pretrained on the ImageNet\n",
        "dataset on the Food101 üçî üåÆ üçï dataset to create a food image classifier.\n",
        "\n",
        "* But first, we will fine tune and test three different architectures: AlexNet, EffNetB2 and ViT-B/16 on a smaller subset of Food101 (3 classes, 200 images/class).\n",
        "\n",
        "* Then, we create and train an EffNetB2 instance on a larger subset of Food101 (101 classes, 200 images/class).\n",
        "\n",
        "* We then deploy this model on hugging face spaces via gradio."
      ],
      "metadata": {
        "id": "Twfai9AHpH_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Setup"
      ],
      "metadata": {
        "id": "ZrTlyWtf8dUn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR0cFOxixK-n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "!pip install -q torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/TensorCruncher/food-image-classifier\n",
        "!mv food-image-classifier/utils .\n",
        "!rm -rf food-image-classifier"
      ],
      "metadata": {
        "id": "cXBqBU8Tx8PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import data\n",
        "from utils import engine\n",
        "from utils import misc\n",
        "from utils import model\n",
        "from utils import predict"
      ],
      "metadata": {
        "id": "kl6WkcIKyok3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "729XPO_G9Nvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "86qOFdcGF2mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Downloading the Data"
      ],
      "metadata": {
        "id": "ZezR57C78ipR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_20_percent_path = data.download_data(source=\"https://github.com/TensorCruncher/food-image-classifier/raw/refs/heads/main/data/pizza_samosa_tacos_20_percent.zip\",\n",
        "                                          destination=\"pizza_samosa_tacos_20_percent\")"
      ],
      "metadata": {
        "id": "z7Q4TzxV6Tso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_20_percent_path"
      ],
      "metadata": {
        "id": "gP7nEWAp6pzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = data_20_percent_path / \"train\"\n",
        "test_dir = data_20_percent_path / \"test\""
      ],
      "metadata": {
        "id": "4oQWC27O7foz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. AlexNet"
      ],
      "metadata": {
        "id": "YM0ORDOf82W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet, alexnet_transforms = model.create_alexnet_model(num_classes=3,\n",
        "                                                         seed=42)"
      ],
      "metadata": {
        "id": "eooenonF88D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(alexnet,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "_ZVEUX159IBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader_alexnet, test_dataloader_alexnet, class_names = data.create_dataloaders(train_dir=train_dir,\n",
        "                                                                                         test_dir=test_dir,\n",
        "                                                                                         transform=alexnet_transforms,\n",
        "                                                                                         batch_size=32)"
      ],
      "metadata": {
        "id": "EEQ27aBS9MV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = engine.create_writer(experiment_name=\"data_20_percent\",\n",
        "                              model_name=\"alexnet\",\n",
        "                              extra=\"10_epochs\")"
      ],
      "metadata": {
        "id": "Lf_jgAX-9gVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=alexnet.parameters(),\n",
        "                             lr=1e-3)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "misc.set_seeds()\n",
        "alexnet_results = engine.train(model=alexnet,\n",
        "                               train_dataloader=train_dataloader_alexnet,\n",
        "                               test_dataloader=test_dataloader_alexnet,\n",
        "                               epochs=10,\n",
        "                               optimizer=optimizer,\n",
        "                               loss_fn=loss_fn,\n",
        "                               device=device,\n",
        "                               writer=writer)"
      ],
      "metadata": {
        "id": "MkZBDvaA9mfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "LrGAwV-V92yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misc.save_model(model=alexnet,\n",
        "                target_dir=\"models\",\n",
        "                model_name=\"pretrained_alexnet_feature_extractor_pizza_samosa_tacos_20_percent.pth\")"
      ],
      "metadata": {
        "id": "h904gAIw99UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_alexnet_model_size = Path(\"models/pretrained_alexnet_feature_extractor_pizza_samosa_tacos_20_percent.pth\").stat().st_size // (1024*1024)\n",
        "print(f\"Pretrained Alexnet feature extractor model size: {pretrained_alexnet_model_size} MB\")"
      ],
      "metadata": {
        "id": "LYbSEMbU-EBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_total_params = sum(torch.numel(param) for param in alexnet.parameters())\n",
        "alexnet_total_params"
      ],
      "metadata": {
        "id": "2OPArbDg-Nx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_stats = {\"test_loss\": alexnet_results[\"test_loss\"][-1],\n",
        "                  \"test_acc\": alexnet_results[\"test_acc\"][-1],\n",
        "                  \"number_of_parameters\": alexnet_total_params,\n",
        "                  \"model_size (MB)\": pretrained_alexnet_model_size}\n",
        "alexnet_stats"
      ],
      "metadata": {
        "id": "nOe0Cwk3-Q3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"models/pretrained_alexnet_feature_extractor_pizza_samosa_tacos_20_percent.pth\")"
      ],
      "metadata": {
        "id": "wxbXlnII9Ojr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. EffNetB2"
      ],
      "metadata": {
        "id": "Dc3qJGfd8pgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2, effnetb2_transforms = model.create_effnetb2_model(num_classes=3,\n",
        "                                                            seed=42)"
      ],
      "metadata": {
        "id": "WkfZxWte7tf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(effnetb2,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "21fElAuf8ZbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader_effnetb2, test_dataloader_effnetb2, class_names = data.create_dataloaders(train_dir=train_dir,\n",
        "                                                                                           test_dir=test_dir,\n",
        "                                                                                           transform=effnetb2_transforms,\n",
        "                                                                                           batch_size=32)"
      ],
      "metadata": {
        "id": "-owqPabQ8j3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = engine.create_writer(experiment_name=\"data_20_percent\",\n",
        "                              model_name=\"effnetb2\",\n",
        "                              extra=\"10_epochs\")"
      ],
      "metadata": {
        "id": "ozPMyQ529gIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=effnetb2.parameters(),\n",
        "                             lr=1e-3)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "misc.set_seeds()\n",
        "effnetb2_results = engine.train(model=effnetb2,\n",
        "                                train_dataloader=train_dataloader_effnetb2,\n",
        "                                test_dataloader=test_dataloader_effnetb2,\n",
        "                                epochs=10,\n",
        "                                optimizer=optimizer,\n",
        "                                loss_fn=loss_fn,\n",
        "                                device=device,\n",
        "                                writer=writer)"
      ],
      "metadata": {
        "id": "Xy6MVb8l85_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "XLOr67z79c1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misc.save_model(model=effnetb2,\n",
        "                target_dir=\"models\",\n",
        "                model_name=\"pretrained_effnetb2_feature_extractor_pizza_samosa_tacos_20_percent.pth\")"
      ],
      "metadata": {
        "id": "mVrSCwzpBNWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_effnetb2_model_size = Path(\"models/pretrained_effnetb2_feature_extractor_pizza_samosa_tacos_20_percent.pth\").stat().st_size // (1024*1024)\n",
        "print(f\"Pretrained EffNetB2 feature extractor model size: {pretrained_effnetb2_model_size} MB\")"
      ],
      "metadata": {
        "id": "BZgzlby2DgmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_total_params = sum(torch.numel(param) for param in effnetb2.parameters())\n",
        "effnetb2_total_params"
      ],
      "metadata": {
        "id": "U_8dBBdPD3s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_stats = {\"test_loss\": effnetb2_results[\"test_loss\"][-1],\n",
        "                  \"test_acc\": effnetb2_results[\"test_acc\"][-1],\n",
        "                  \"number_of_parameters\": effnetb2_total_params,\n",
        "                  \"model_size (MB)\": pretrained_effnetb2_model_size}\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "id": "kYJYlRmJEAJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"models/pretrained_effnetb2_feature_extractor_pizza_samosa_tacos_20_percent.pth\")"
      ],
      "metadata": {
        "id": "s21p44EY9Zp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. ViT-B/16"
      ],
      "metadata": {
        "id": "cfyH7DYu8wG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vit, vit_transforms = model.create_vit_model(num_classes=3,\n",
        "                                             seed=42)"
      ],
      "metadata": {
        "id": "tVuvI9k-EEO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(vit,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "x71PTfKF-ZKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader_vit, test_dataloader_vit, class_names = data.create_dataloaders(train_dir=train_dir,\n",
        "                                                                                 test_dir=test_dir,\n",
        "                                                                                 transform=vit_transforms,\n",
        "                                                                                 batch_size=32)"
      ],
      "metadata": {
        "id": "N7fSchwO-eXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = engine.create_writer(experiment_name=\"data_20_percent\",\n",
        "                              model_name=\"vit\",\n",
        "                              extra=\"10_epochs\")"
      ],
      "metadata": {
        "id": "l5KhfhJ8-3mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=vit.parameters(),\n",
        "                             lr=1e-3)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "misc.set_seeds()\n",
        "vit_results = engine.train(model=vit,\n",
        "                           train_dataloader=train_dataloader_vit,\n",
        "                           test_dataloader=test_dataloader_vit,\n",
        "                           epochs=10,\n",
        "                           optimizer=optimizer,\n",
        "                           loss_fn=loss_fn,\n",
        "                           device=device,\n",
        "                           writer=writer)"
      ],
      "metadata": {
        "id": "YmMZ8IIl--lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "as5QDC1E_KRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misc.save_model(model=vit,\n",
        "                target_dir=\"models\",\n",
        "                model_name=\"pretrained_vit_feature_extractor_pizza_samosa_tacos_20_percent.pth\")"
      ],
      "metadata": {
        "id": "xY1e7yv__OiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_vit_model_size = Path(\"models/pretrained_vit_feature_extractor_pizza_samosa_tacos_20_percent.pth\").stat().st_size // (1024*1024)\n",
        "print(f\"Pretrained ViT feature extractor model size: {pretrained_vit_model_size} MB\")"
      ],
      "metadata": {
        "id": "hghhe81M_T_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_total_params = sum(torch.numel(param) for param in vit.parameters())\n",
        "vit_total_params"
      ],
      "metadata": {
        "id": "um-YT5Sh_cl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_stats = {\"test_loss\": vit_results[\"test_loss\"][-1],\n",
        "             \"test_acc\": vit_results[\"test_acc\"][-1],\n",
        "             \"number_of_parameters\": vit_total_params,\n",
        "             \"model_size (MB)\": pretrained_vit_model_size}\n",
        "vit_stats"
      ],
      "metadata": {
        "id": "1NM9upTKYjKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"models/pretrained_vit_feature_extractor_pizza_samosa_tacos_20_percent.pth\")"
      ],
      "metadata": {
        "id": "BP1bmb-G9gaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Calculating the inference time / image for our models"
      ],
      "metadata": {
        "id": "x3hCinseZZAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[INFO] Finding all filepaths ending with '.jpg' in directory: {test_dir}\")\n",
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_data_paths[:5]"
      ],
      "metadata": {
        "id": "ub4bGIw4ZfRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Timing Alexnet"
      ],
      "metadata": {
        "id": "mAg2eZaF5fcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_test_pred_dicts = predict.pred_and_store(paths=test_data_paths,\n",
        "                                         model=alexnet,\n",
        "                                         transform=alexnet_transforms,\n",
        "                                         class_names=class_names,\n",
        "                                         device=\"cpu\")"
      ],
      "metadata": {
        "id": "kOcxEGDJ5iAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_test_pred_dicts[:2]"
      ],
      "metadata": {
        "id": "3GkiCUJj5h5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_test_pred_df = pd.DataFrame(alexnet_test_pred_dicts)\n",
        "alexnet_test_pred_df.head()"
      ],
      "metadata": {
        "id": "aG0wGjbk5hyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_test_pred_df.correct.value_counts()"
      ],
      "metadata": {
        "id": "GP19JMMy5hpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_average_time_per_pred = round(alexnet_test_pred_df.time_for_pred.mean(), 4)\n",
        "print(f\"Alexnet average time per prediction: {alexnet_average_time_per_pred} seconds\")"
      ],
      "metadata": {
        "id": "8lRqsZhS5hiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_stats[\"time_per_pred_cpu\"] = float(alexnet_average_time_per_pred)\n",
        "alexnet_stats"
      ],
      "metadata": {
        "id": "3s_-zgX95hat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Timing EffNetB2"
      ],
      "metadata": {
        "id": "zDwNGhor5IDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred_dicts = predict.pred_and_store(paths=test_data_paths,\n",
        "                                          model=effnetb2,\n",
        "                                          transform=effnetb2_transforms,\n",
        "                                          class_names=class_names,\n",
        "                                          device=\"cpu\")"
      ],
      "metadata": {
        "id": "UXhXY75D4xMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred_dicts[:2]"
      ],
      "metadata": {
        "id": "8G9fDgkL43LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred_df = pd.DataFrame(effnetb2_test_pred_dicts)\n",
        "effnetb2_test_pred_df.head()"
      ],
      "metadata": {
        "id": "lNP9GrB145gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred_df.correct.value_counts()"
      ],
      "metadata": {
        "id": "dVIq_Thi48Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_average_time_per_pred = round(effnetb2_test_pred_df.time_for_pred.mean(), 4)\n",
        "print(f\"EffNetB2 average time per prediction: {effnetb2_average_time_per_pred} seconds\")"
      ],
      "metadata": {
        "id": "3_KqPMJt494H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_stats[\"time_per_pred_cpu\"] = float(effnetb2_average_time_per_pred)\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "id": "9TlZ1d4b5ADi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 Timing ViT"
      ],
      "metadata": {
        "id": "7RqFZLK85EnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vit_test_pred_dicts = predict.pred_and_store(paths=test_data_paths,\n",
        "                                     model=vit,\n",
        "                                     transform=vit_transforms,\n",
        "                                     class_names=class_names,\n",
        "                                     device=\"cpu\")"
      ],
      "metadata": {
        "id": "cYncbfJn5G8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_test_pred_dicts[:2]"
      ],
      "metadata": {
        "id": "irAkaaCV5QYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_test_pred_df = pd.DataFrame(vit_test_pred_dicts)\n",
        "vit_test_pred_df.head()"
      ],
      "metadata": {
        "id": "l7G6oYcc5PVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_test_pred_df.correct.value_counts()"
      ],
      "metadata": {
        "id": "g8aE8vRc5PLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_average_time_per_pred = round(vit_test_pred_df.time_for_pred.mean(), 4)\n",
        "print(f\"ViT average time per prediction: {vit_average_time_per_pred} seconds\")"
      ],
      "metadata": {
        "id": "EOhuoTcz5PDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_stats[\"time_per_pred_cpu\"] = float(vit_average_time_per_pred)\n",
        "vit_stats"
      ],
      "metadata": {
        "id": "n8toLXwT5OwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Comparing model size, performance and inference time"
      ],
      "metadata": {
        "id": "BqajaarF6Hgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([alexnet_stats, effnetb2_stats, vit_stats])\n",
        "\n",
        "df[\"model\"] = [\"AlexNet\", \"EffNetB2\", \"ViT\"]\n",
        "\n",
        "df[\"test_acc\"] = round(df[\"test_acc\"] * 100, 2)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "6utHsMsZ6MSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df = df.set_index(\"model\")\n",
        "\n",
        "vit_to_effnet = model_df.loc[\"ViT\"] / model_df.loc[\"EffNetB2\"]\n",
        "vit_to_alexnet = model_df.loc[\"ViT\"] / model_df.loc[\"AlexNet\"]\n",
        "effnet_to_alexnet = model_df.loc[\"EffNetB2\"] / model_df.loc[\"AlexNet\"]\n",
        "\n",
        "pd.DataFrame({\n",
        "    \"ViT to EffNetB2\": vit_to_effnet,\n",
        "    \"EffNetB2 to AlexNet\": effnet_to_alexnet,\n",
        "    \"ViT to AlexNet\": vit_to_alexnet\n",
        "}).T"
      ],
      "metadata": {
        "id": "g87mdC5A63Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "scatter = ax.scatter(data=df,\n",
        "                     x=\"time_per_pred_cpu\",\n",
        "                     y=\"test_acc\",\n",
        "                     c=[\"blue\", \"orange\", \"green\"],\n",
        "                     s=\"model_size (MB)\")\n",
        "\n",
        "ax.set_title(\"Inference Speed vs Performance\", fontsize=18)\n",
        "ax.set_xlabel(\"Prediction time per image (seconds)\", fontsize=14)\n",
        "ax.set_ylabel(\"Test accuracy (%)\", fontsize=14)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.grid(True)\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    ax.annotate(text=row[\"model\"],\n",
        "                xy=(row[\"time_per_pred_cpu\"]+0.0006, row[\"test_acc\"]+0.03),\n",
        "                size=12)\n",
        "\n",
        "handles, labels = scatter.legend_elements(prop=\"sizes\", alpha=0.5)\n",
        "model_size_legend = ax.legend(handles,\n",
        "                              labels,\n",
        "                              loc=\"lower right\",\n",
        "                              title=\"Model size (MB)\",\n",
        "                              fontsize=12)\n",
        "\n",
        "!mdkir images/\n",
        "plt.savefig(\"model-inference-time-vs-accuracy.jpg\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qM9ZdVtW6u45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"model-inference-time-vs-accuracy.jpg\")"
      ],
      "metadata": {
        "id": "T4DukHUZLIMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see in the above analysis that EffNetB2 provides slightly higher test accuracy for about 1/10 th the model size compared to AlexNet. This is advantageous despite it taking twice the time per prediction.\n",
        "\n",
        "While ViT gives the best test accuracy, its model size is also more than 10x the EffNet model size. Further, it takes about 4x the time to make a prediction.\n",
        "\n",
        "Keeping in mind the above factors, we will use the EffNetB2 architecture going forward to train on a larger subset of the Food101 dataset. It will still have 20% of the data per class, but we will use all 101 classes instead of of just the three we have used so far."
      ],
      "metadata": {
        "id": "EaqVSAtHANeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Training the model on a larger subset of Food101"
      ],
      "metadata": {
        "id": "PBpVOxO3TcuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_food101, effnetb2_transforms = model.create_effnetb2_model(num_classes=101)"
      ],
      "metadata": {
        "id": "3tXpxttRTkhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(effnetb2_food101,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "UOVlIPH4tOVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food101_train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.TrivialAugmentWide(),\n",
        "    effnetb2_transforms,\n",
        "])"
      ],
      "metadata": {
        "id": "4nNcrq2StSnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training transforms:\\n{food101_train_transforms}\\n\")\n",
        "print(f\"Testing transforms:\\n{effnetb2_transforms}\")"
      ],
      "metadata": {
        "id": "jOc1UtXvtVGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path(\"data\")\n",
        "\n",
        "train_data = datasets.Food101(root=data_dir,\n",
        "                              split=\"train\",\n",
        "                              transform=food101_train_transforms,\n",
        "                              download=True)\n",
        "\n",
        "test_data = datasets.Food101(root=data_dir,\n",
        "                             split=\"test\",\n",
        "                             transform=effnetb2_transforms,\n",
        "                             download=True)"
      ],
      "metadata": {
        "id": "ngwHUf83tYUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food101_class_names = train_data.classes\n",
        "\n",
        "food101_class_names[:10]"
      ],
      "metadata": {
        "id": "A1KsyDQqta1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_food101_20_percent, _ = data.split_dataset(dataset=train_data,\n",
        "                                                 split_size=0.2)\n",
        "\n",
        "test_data_food101_20_percent, _ = data.split_dataset(dataset=test_data,\n",
        "                                                split_size=0.2)\n",
        "\n",
        "len(train_data_food101_20_percent), len(test_data_food101_20_percent)"
      ],
      "metadata": {
        "id": "bcDd01arthlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WORKERS = 2 if os.cpu_count() <= 4 else 4\n",
        "\n",
        "train_dataloader_food101_20_percent = torch.utils.data.DataLoader(train_data_food101_20_percent,\n",
        "                                                                  batch_size=32,\n",
        "                                                                  shuffle=True,\n",
        "                                                                  num_workers=NUM_WORKERS)\n",
        "\n",
        "test_dataloader_food101_20_percent = torch.utils.data.DataLoader(test_data_food101_20_percent,\n",
        "                                                                 batch_size=32,\n",
        "                                                                 shuffle=False,\n",
        "                                                                 num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "TPNFau6dtj-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = engine.create_writer(experiment_name=\"food_101_20_percent\",\n",
        "                              model_name=\"effnetb2\",\n",
        "                              extra=\"10_epochs\")"
      ],
      "metadata": {
        "id": "gaYHK9LOtwBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=effnetb2_food101.parameters(),\n",
        "                             lr=1e-3)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "misc.set_seeds()\n",
        "effnetb2_food101_results = engine.train(model=effnetb2_food101,\n",
        "                                        train_dataloader=train_dataloader_food101_20_percent,\n",
        "                                        test_dataloader=test_dataloader_food101_20_percent,\n",
        "                                        optimizer=optimizer,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        epochs=10,\n",
        "                                        device=device,\n",
        "                                        writer=writer)"
      ],
      "metadata": {
        "id": "ejmyZ_A5tmtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "fYoyTqB9t1zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_food101_model_path = \"pretrained_effnetb2_feature_extractor_food101_20_percent.pth\"\n",
        "\n",
        "misc.save_model(model=effnetb2_food101,\n",
        "                target_dir=\"models\",\n",
        "                model_name=effnetb2_food101_model_path)"
      ],
      "metadata": {
        "id": "6zUv1g6xt2Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_food101_total_params = sum(torch.numel(param) for param in effnetb2_food101.parameters())\n",
        "effnetb2_food101_total_params"
      ],
      "metadata": {
        "id": "WAhBR6Srm6xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_effnetb2_food101_model_size = Path(\"models\", effnetb2_food101_model_path).stat().st_size // (1024*1024)\n",
        "print(f\"Pretrained EffNetB2 feature extractor Food101 model size: {pretrained_effnetb2_food101_model_size} MB\")"
      ],
      "metadata": {
        "id": "rAmXr0vGuAIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_food101_stats = {\"test_loss\": effnetb2_food101_results[\"test_loss\"][-1],\n",
        "                          \"test_acc\": effnetb2_food101_results[\"test_acc\"][-1],\n",
        "                          \"number_of_parameters\": effnetb2_food101_total_params,\n",
        "                          \"model_size (MB)\": pretrained_effnetb2_food101_model_size}\n",
        "effnetb2_food101_stats"
      ],
      "metadata": {
        "id": "NTiatj8HnUb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"models/pretrained_effnetb2_feature_extractor_food101_20_percent.pth\")"
      ],
      "metadata": {
        "id": "z7J-cc5J9uCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Creating Gradio Demo"
      ],
      "metadata": {
        "id": "7F7KuwZFMGFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food_classifier_demo_path = Path(\"demos/food_classifier/\")\n",
        "\n",
        "food_classifier_demo_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "(food_classifier_demo_path / \"examples\").mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "F_PTjSDdMK12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/TensorCruncher/food-image-classifier/main/images/pizza.jpg\n",
        "!wget https://raw.githubusercontent.com/TensorCruncher/food-image-classifier/main/images/samosa.jpg\n",
        "!wget https://raw.githubusercontent.com/TensorCruncher/food-image-classifier/main/images/tacos.jpg\n",
        "!wget https://raw.githubusercontent.com/TensorCruncher/food-image-classifier/main/images/red_velvet_cake.jpg\n",
        "\n",
        "!mv pizza.jpg demos/food_classifier/examples/pizza.jpg\n",
        "!mv samosa.jpg demos/food_classifier/examples/samosa.jpg\n",
        "!mv tacos.jpg demos/food_classifier/examples/tacos.jpg\n",
        "!mv red_velvet_cake.jpg demos/food_classifier/examples/red_velvet_cake.jpg\n",
        "\n",
        "!mv models/pretrained_effnetb2_feature_extractor_food101_20_percent.pth demos/food_classifier"
      ],
      "metadata": {
        "id": "CaZbVdbfNY7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food101_class_names[:10]"
      ],
      "metadata": {
        "id": "1MahPrB7NeB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food_classifier_class_names_path = food_classifier_demo_path / \"class_names.txt\"\n",
        "\n",
        "with open(food_classifier_class_names_path, \"w\") as f:\n",
        "    print(f\"[INFO] Saving Food101 class names to {food_classifier_class_names_path}\")\n",
        "    f.write(\"\\n\".join(food101_class_names))"
      ],
      "metadata": {
        "id": "vEZbPOGCNd6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(food_classifier_class_names_path, \"r\") as f:\n",
        "    food101_class_names_loaded = [food.strip() for food in  f.readlines()]\n",
        "\n",
        "food101_class_names_loaded[:5]"
      ],
      "metadata": {
        "id": "hReMzQFKNdz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/food_classifier/model.py\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "def create_effnetb2_model(num_classes:int=3,\n",
        "                          seed:int=42):\n",
        "    \"\"\"Creates an EfficientNetB2 feature extractor model and transforms.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int, optional): number of classes in the classifier head.\n",
        "            Defaults to 3.\n",
        "        seed (int, optional): random seed value. Defaults to 42.\n",
        "\n",
        "    Returns:\n",
        "        model (torch.nn.Module): EffNetB2 feature extractor model.\n",
        "        transforms (torchvision.transforms): EffNetB2 image transforms.\n",
        "    \"\"\"\n",
        "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "    transforms = weights.transforms()\n",
        "    model = torchvision.models.efficientnet_b2(weights=weights)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.3, inplace=True),\n",
        "        nn.Linear(in_features=1408, out_features=num_classes),\n",
        "    )\n",
        "\n",
        "    return model, transforms"
      ],
      "metadata": {
        "id": "J5a92gfXNdtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/food_classifier/app.py\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from model import create_effnetb2_model\n",
        "from timeit import default_timer as timer\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "with open(\"class_names.txt\", \"r\") as f:\n",
        "    class_names = [food_name.strip() for food_name in  f.readlines()]\n",
        "\n",
        "effnetb2, effnetb2_transforms = create_effnetb2_model(\n",
        "    num_classes=101,\n",
        ")\n",
        "\n",
        "effnetb2.load_state_dict(\n",
        "    torch.load(\n",
        "        f=\"pretrained_effnetb2_feature_extractor_food101_20_percent.pth\",\n",
        "        map_location=torch.device(\"cpu\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "def predict(img) -> Tuple[Dict, float]:\n",
        "    \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
        "    \"\"\"\n",
        "    start_time = timer()\n",
        "\n",
        "    img = effnetb2_transforms(img).unsqueeze(0)\n",
        "\n",
        "    effnetb2.eval()\n",
        "    with torch.inference_mode():\n",
        "        pred_probs = torch.softmax(effnetb2(img), dim=1)\n",
        "\n",
        "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "    pred_time = round(timer() - start_time, 5)\n",
        "\n",
        "    return pred_labels_and_probs, pred_time\n",
        "\n",
        "title = \"Food Image Classifier üçï üçî üåÆ üç∞\"\n",
        "description = \"An EfficientNetB2 model that classifies images of food into [101 different classes](https://github.com/TensorCruncher/food-image-classifier/blob/main/data/food101_class_names.txt).\"\n",
        "article = \"View on [GitHub](https://github.com/TensorCruncher/food-image-classifier).\"\n",
        "\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=5, label=\"Predictions\"),\n",
        "        gr.Number(label=\"Prediction time (s)\"),\n",
        "    ],\n",
        "    examples=example_list,\n",
        "    title=title,\n",
        "    description=description,\n",
        "    article=article,\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "MwcV78wTNdh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/food_classifier/requirements.txt\n",
        "torch\n",
        "torchvision\n",
        "gradio"
      ],
      "metadata": {
        "id": "-3bNsYWSNdZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd demos/food_classifier && zip -r ../food_classifier.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\"\n",
        "\n",
        "files.download(\"demos/food_classifier.zip\")"
      ],
      "metadata": {
        "id": "4NuOZR8KNdQ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}